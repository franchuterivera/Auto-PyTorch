
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "examples/example_image_classification.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_examples_example_image_classification.py>`
        to download the full example code or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_examples_example_image_classification.py:


======================
Image Classification
======================

.. GENERATED FROM PYTHON SOURCE LINES 6-55




.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ../datasets/FashionMNIST/raw/train-images-idx3-ubyte.gz
    0it [00:00, ?it/s]      0%|          | 0/26421880 [00:00<?, ?it/s]      0%|          | 16384/26421880 [00:00<03:09, 139611.87it/s]      0%|          | 49152/26421880 [00:00<01:59, 221425.84it/s]      0%|          | 106496/26421880 [00:00<01:12, 362263.63it/s]      1%|          | 229376/26421880 [00:00<00:40, 640751.27it/s]      2%|1         | 466944/26421880 [00:00<00:22, 1149185.01it/s]      4%|3         | 950272/26421880 [00:00<00:11, 2169317.82it/s]      7%|7         | 1916928/26421880 [00:01<00:05, 4166545.21it/s]     15%|#4        | 3833856/26421880 [00:01<00:02, 8050379.00it/s]     26%|##6       | 6922240/26421880 [00:01<00:01, 13760210.71it/s]     38%|###8      | 10059776/26421880 [00:01<00:00, 17764805.66it/s]     50%|####9     | 13189120/26421880 [00:01<00:00, 20475376.23it/s]     62%|######1   | 16326656/26421880 [00:01<00:00, 22366290.53it/s]     73%|#######3  | 19357696/26421880 [00:01<00:00, 23404774.29it/s]     85%|########5 | 22462464/26421880 [00:01<00:00, 24293806.86it/s]     97%|#########6| 25550848/26421880 [00:02<00:00, 24883703.11it/s]Extracting ../datasets/FashionMNIST/raw/train-images-idx3-ubyte.gz to ../datasets/FashionMNIST/raw
    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ../datasets/FashionMNIST/raw/train-labels-idx1-ubyte.gz

    0it [00:00, ?it/s][A
      0%|          | 0/29515 [00:00<?, ?it/s][A
     56%|#####5    | 16384/29515 [00:00<00:00, 140460.25it/s][AExtracting ../datasets/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ../datasets/FashionMNIST/raw
    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ../datasets/FashionMNIST/raw/t10k-images-idx3-ubyte.gz


    0it [00:00, ?it/s][A[A

      0%|          | 0/4422102 [00:00<?, ?it/s][A[A

      0%|          | 16384/4422102 [00:00<00:31, 141525.07it/s][A[A

      1%|1         | 49152/4422102 [00:00<00:19, 223912.23it/s][A[A

      2%|2         | 106496/4422102 [00:00<00:12, 346634.18it/s][A[A

      5%|5         | 229376/4422102 [00:00<00:06, 626456.80it/s][A[A

     11%|#         | 466944/4422102 [00:00<00:03, 1136169.09it/s][A[A

     21%|##1       | 950272/4422102 [00:00<00:01, 2161219.28it/s][A[A

     43%|####3     | 1916928/4422102 [00:01<00:00, 4168453.93it/s][A[A

     87%|########6 | 3833856/4422102 [00:01<00:00, 8082484.16it/s][A[AExtracting ../datasets/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ../datasets/FashionMNIST/raw
    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ../datasets/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz



    0it [00:00, ?it/s][A[A[A


      0%|          | 0/5148 [00:00<?, ?it/s][A[A[AExtracting ../datasets/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ../datasets/FashionMNIST/raw
    Processing...
    /opt/hostedtoolcache/Python/3.8.7/x64/lib/python3.8/site-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)
      return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)
    Done!
    26427392it [00:04, 5672382.59it/s]                               
    32768it [00:02, 15703.23it/s]                            
    4423680it [00:01, 2585509.69it/s]                             
    8192it [00:00, 18963.63it/s]            
    Pipeline CS:
     ________________________________________ 
    Configuration space object:
      Hyperparameters:
        image_augmenter:GaussianBlur:sigma_min, Type: UniformFloat, Range: [0.0, 3.0], Default: 0.0
        image_augmenter:GaussianBlur:sigma_offset, Type: UniformFloat, Range: [0.0, 3.0], Default: 0.5
        image_augmenter:GaussianBlur:use_augmenter, Type: Categorical, Choices: {True, False}, Default: True
        image_augmenter:GaussianNoise:sigma_offset, Type: UniformFloat, Range: [0.0, 3.0], Default: 0.3
        image_augmenter:GaussianNoise:use_augmenter, Type: Categorical, Choices: {True, False}, Default: True
        image_augmenter:RandomAffine:rotate, Type: UniformInteger, Range: [0, 360], Default: 45
        image_augmenter:RandomAffine:scale_offset, Type: UniformFloat, Range: [0.0, 0.4], Default: 0.2
        image_augmenter:RandomAffine:shear, Type: UniformInteger, Range: [0, 45], Default: 30
        image_augmenter:RandomAffine:translate_percent_offset, Type: UniformFloat, Range: [0.0, 0.4], Default: 0.2
        image_augmenter:RandomAffine:use_augmenter, Type: Categorical, Choices: {True, False}, Default: True
        image_augmenter:RandomCutout:p, Type: UniformFloat, Range: [0.2, 1.0], Default: 0.5
        image_augmenter:RandomCutout:use_augmenter, Type: Categorical, Choices: {True, False}, Default: True
        image_augmenter:Resize:use_augmenter, Type: Categorical, Choices: {True, False}, Default: True
        image_augmenter:ZeroPadAndCrop:percent, Type: UniformFloat, Range: [0.0, 0.5], Default: 0.1
        normalizer:__choice__, Type: Categorical, Choices: {ImageNormalizer, NoNormalizer}, Default: ImageNormalizer
      Conditions:
        image_augmenter:GaussianBlur:sigma_min | image_augmenter:GaussianBlur:use_augmenter == True
        image_augmenter:GaussianBlur:sigma_offset | image_augmenter:GaussianBlur:use_augmenter == True
        image_augmenter:GaussianNoise:sigma_offset | image_augmenter:GaussianNoise:use_augmenter == True
        image_augmenter:RandomAffine:rotate | image_augmenter:RandomAffine:use_augmenter == True
        image_augmenter:RandomAffine:scale_offset | image_augmenter:RandomAffine:use_augmenter == True
        image_augmenter:RandomAffine:shear | image_augmenter:RandomAffine:use_augmenter == True
        image_augmenter:RandomAffine:translate_percent_offset | image_augmenter:RandomAffine:use_augmenter == True
        image_augmenter:RandomCutout:p | image_augmenter:RandomCutout:use_augmenter == True

    Pipeline Random Config:
     ________________________________________ 
    Configuration:
      image_augmenter:GaussianBlur:sigma_min, Value: 0.21949899267445816
      image_augmenter:GaussianBlur:sigma_offset, Value: 1.9531265580610953
      image_augmenter:GaussianBlur:use_augmenter, Value: True
      image_augmenter:GaussianNoise:use_augmenter, Value: False
      image_augmenter:RandomAffine:use_augmenter, Value: False
      image_augmenter:RandomCutout:use_augmenter, Value: False
      image_augmenter:Resize:use_augmenter, Value: True
      image_augmenter:ZeroPadAndCrop:percent, Value: 0.38255113294272386
      normalizer:__choice__, Value: 'ImageNormalizer'

    Fitting the pipeline...
    ________________________________________
            ImageClassificationPipeline
    ________________________________________
    0-) normalizer: 
            ImageNormalizer

    1-) preprocessing: 
            EarlyPreprocessing

    2-) image_augmenter: 
            ImageAugmenter

    ________________________________________






|

.. code-block:: default

    import numpy as np

    import sklearn.model_selection

    import torchvision.datasets

    from autoPyTorch.pipeline.image_classification import ImageClassificationPipeline

    # Get the training data for tabular classification
    trainset = torchvision.datasets.FashionMNIST(root='../datasets/', train=True, download=True)
    data = trainset.data.numpy()
    data = np.expand_dims(data, axis=3)
    # Create a proof of concept pipeline!
    dataset_properties = dict()
    pipeline = ImageClassificationPipeline(dataset_properties=dataset_properties)

    # Train and test split
    train_indices, val_indices = sklearn.model_selection.train_test_split(
        list(range(data.shape[0])),
        random_state=1,
        test_size=0.25,
    )

    # Configuration space
    pipeline_cs = pipeline.get_hyperparameter_search_space()
    print("Pipeline CS:\n", '_' * 40, f"\n{pipeline_cs}")
    config = pipeline_cs.sample_configuration()
    print("Pipeline Random Config:\n", '_' * 40, f"\n{config}")
    pipeline.set_hyperparameters(config)

    # Fit the pipeline
    print("Fitting the pipeline...")

    pipeline.fit(X=dict(X_train=data,
                        is_small_preprocess=True,
                        dataset_properties=dict(mean=np.array([np.mean(data[:, :, :, i]) for i in range(1)]),
                                                std=np.array([np.std(data[:, :, :, i]) for i in range(1)]),
                                                num_classes=10,
                                                num_features=data.shape[1] * data.shape[2],
                                                image_height=data.shape[1],
                                                image_width=data.shape[2],
                                                is_small_preprocess=True),
                        train_indices=train_indices,
                        val_indices=val_indices,
                        )
                 )

    # Showcase some components of the pipeline
    print(pipeline)


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  10.547 seconds)


.. _sphx_glr_download_examples_example_image_classification.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example


  .. container:: binder-badge

    .. image:: images/binder_badge_logo.svg
      :target: https://mybinder.org/v2/gh/automl/Auto-PyTorch/refactor_development?urlpath=lab/tree/notebooks/examples/example_image_classification.ipynb
      :alt: Launch binder
      :width: 150 px


  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: example_image_classification.py <example_image_classification.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: example_image_classification.ipynb <example_image_classification.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
